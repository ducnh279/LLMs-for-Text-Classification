{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "499fc531",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "papermill": {
          "duration": 0.008006,
          "end_time": "2024-04-22T23:11:46.414405",
          "exception": false,
          "start_time": "2024-04-22T23:11:46.406399",
          "status": "completed"
        },
        "tags": [],
        "id": "499fc531"
      },
      "source": [
        "# Pip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece -q\n",
        "!pip install transformers -q\n",
        "!pip install accelerate -q\n",
        "!pip install peft -q\n",
        "!pip install bitsandbytes -q\n",
        "!pip install lightning -q\n",
        "!pip install flash-attn --no-build-isolation -q"
      ],
      "metadata": {
        "id": "jgUQbiVhI6iw"
      },
      "id": "jgUQbiVhI6iw",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "924b602f",
      "metadata": {
        "papermill": {
          "duration": 0.00706,
          "end_time": "2024-04-22T23:12:30.270021",
          "exception": false,
          "start_time": "2024-04-22T23:12:30.262961",
          "status": "completed"
        },
        "tags": [],
        "id": "924b602f"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "04dd9cfd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T23:12:30.286229Z",
          "iopub.status.busy": "2024-04-22T23:12:30.285840Z",
          "iopub.status.idle": "2024-04-22T23:12:39.353797Z",
          "shell.execute_reply": "2024-04-22T23:12:39.352992Z"
        },
        "papermill": {
          "duration": 9.079057,
          "end_time": "2024-04-22T23:12:39.356253",
          "exception": false,
          "start_time": "2024-04-22T23:12:30.277196",
          "status": "completed"
        },
        "tags": [],
        "id": "04dd9cfd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    get_linear_schedule_with_warmup,\n",
        "    get_cosine_schedule_with_warmup\n",
        ")\n",
        "\n",
        "import os\n",
        "import time\n",
        "import zipfile\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import log_loss, accuracy_score\n",
        "import lightning as L\n",
        "\n",
        "from peft import (\n",
        "    get_peft_config,\n",
        "    get_peft_model,\n",
        "    LoraConfig,\n",
        "    TaskType\n",
        ")\n",
        "\n",
        "tqdm.pandas()\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get data"
      ],
      "metadata": {
        "id": "4jU03Y0TrP8f"
      },
      "id": "4jU03Y0TrP8f"
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "def download_and_unzip(url, zip_path, extracted_path, data_file_path):\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
        "        return\n",
        "\n",
        "    # Downloading the file\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        with open(zip_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "\n",
        "    # Unzipping the file\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "\n",
        "    # Add .tsv file extension\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path)\n",
        "    print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "download_and_unzip(url, zip_path, extracted_path, data_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLvpzJU6kYCO",
        "outputId": "511b2c11-5850-4c7c-a825-8b77afc169c6"
      },
      "id": "WLvpzJU6kYCO",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"target\", \"text\"])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "57_fyXXjkexm",
        "outputId": "8710a364-a99f-48b6-eaf7-d4bc08e66925"
      },
      "id": "57_fyXXjkexm",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     target                                               text\n",
              "0       ham  Go until jurong point, crazy.. Available only ...\n",
              "1       ham                      Ok lar... Joking wif u oni...\n",
              "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3       ham  U dun say so early hor... U c already then say...\n",
              "4       ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...     ...                                                ...\n",
              "5567   spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568    ham               Will ü b going to esplanade fr home?\n",
              "5569    ham  Pity, * was in mood for that. So...any other s...\n",
              "5570    ham  The guy did some bitching but I acted like i'd...\n",
              "5571    ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b023d617-ee82-4e5b-91aa-f121c01c6700\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b023d617-ee82-4e5b-91aa-f121c01c6700')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b023d617-ee82-4e5b-91aa-f121c01c6700 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b023d617-ee82-4e5b-91aa-f121c01c6700');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-63a0b0c8-c33d-4c3d-af42-4345c31b3bb8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-63a0b0c8-c33d-4c3d-af42-4345c31b3bb8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-63a0b0c8-c33d-4c3d-af42-4345c31b3bb8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_49629b7e-6d47-409c-afab-d48400483a25\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_49629b7e-6d47-409c-afab-d48400483a25 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_balanced_dataset(df):\n",
        "\n",
        "    # Count the instances of \"spam\"\n",
        "    num_spam = df[df[\"target\"] == \"spam\"].shape[0]\n",
        "\n",
        "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
        "    ham_subset = df[df[\"target\"] == \"ham\"].sample(num_spam, random_state=123)\n",
        "\n",
        "    # Combine ham \"subset\" with \"spam\"\n",
        "    balanced_df = pd.concat([ham_subset, df[df[\"target\"] == \"spam\"]])\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"target\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc_Sp9OZvBNP",
        "outputId": "7842216b-0024-4e9f-e540-a73f6e66df6b"
      },
      "id": "Kc_Sp9OZvBNP",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df['target'] = df.target.map({'spam': 1, 'ham': 0})"
      ],
      "metadata": {
        "id": "ieBD0VyYvZRm"
      },
      "id": "ieBD0VyYvZRm",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "    # Shuffle the entire DataFrame\n",
        "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "\n",
        "    # Calculate split indices\n",
        "    train_end = int(len(df) * train_frac)\n",
        "    validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        "    # Split the DataFrame\n",
        "    train_df = df[:train_end]\n",
        "    validation_df = df[train_end:validation_end]\n",
        "    test_df = df[validation_end:]\n",
        "\n",
        "    return train_df, validation_df, test_df\n",
        "\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
        "# Test size is implied to be 0.2 as the remainder\n",
        "\n",
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ],
      "metadata": {
        "id": "5ZSF2NpOvMs2"
      },
      "id": "5ZSF2NpOvMs2",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "60deb920",
      "metadata": {
        "papermill": {
          "duration": 0.007691,
          "end_time": "2024-04-22T23:12:40.371231",
          "exception": false,
          "start_time": "2024-04-22T23:12:40.363540",
          "status": "completed"
        },
        "tags": [],
        "id": "60deb920"
      },
      "source": [
        "# Load tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e2a5586a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T23:12:40.389191Z",
          "iopub.status.busy": "2024-04-22T23:12:40.388389Z",
          "iopub.status.idle": "2024-04-22T23:12:40.525522Z",
          "shell.execute_reply": "2024-04-22T23:12:40.524408Z"
        },
        "papermill": {
          "duration": 0.149076,
          "end_time": "2024-04-22T23:12:40.528192",
          "exception": false,
          "start_time": "2024-04-22T23:12:40.379116",
          "status": "completed"
        },
        "tags": [],
        "id": "e2a5586a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cc50b36-1a5f-42ff-c3a8-8f1926facdee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Initialize tokenizer with model ID and authentication token\n",
        "model_id = 'h2oai/h2o-danube-1.8b-chat'\n",
        "hf_token = 'hf_' # Replace your token here on huggingface\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# Set padding token to end-of-sequence token and configure padding side\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = 'left'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split data"
      ],
      "metadata": {
        "id": "jWLj2R2Q4uiw"
      },
      "id": "jWLj2R2Q4uiw"
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "val = pd.read_csv('validation.csv')"
      ],
      "metadata": {
        "id": "yOOWKsDvvqfF"
      },
      "id": "yOOWKsDvvqfF",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'] = tokenizer.bos_token + train['text']\n",
        "test['text'] = tokenizer.bos_token + test['text']\n",
        "val['text'] = tokenizer.bos_token + val['text']"
      ],
      "metadata": {
        "id": "a232xwiyFMe4"
      },
      "id": "a232xwiyFMe4",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = tokenizer(train.text[0], add_special_tokens=False).input_ids\n",
        "tokenizer.decode(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pvIUdJUCHXx_",
        "outputId": "d4889d47-e068-4e85-9cdb-14943fa4aa1e"
      },
      "id": "pvIUdJUCHXx_",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> Dude how do you like the buff wind.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c87eca07",
      "metadata": {
        "papermill": {
          "duration": 0.008283,
          "end_time": "2024-04-22T23:14:26.773511",
          "exception": false,
          "start_time": "2024-04-22T23:14:26.765228",
          "status": "completed"
        },
        "tags": [],
        "id": "c87eca07"
      },
      "source": [
        "# Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c652a192",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T23:14:26.791438Z",
          "iopub.status.busy": "2024-04-22T23:14:26.791103Z",
          "iopub.status.idle": "2024-04-22T23:14:26.797238Z",
          "shell.execute_reply": "2024-04-22T23:14:26.796383Z"
        },
        "papermill": {
          "duration": 0.017497,
          "end_time": "2024-04-22T23:14:26.799251",
          "exception": false,
          "start_time": "2024-04-22T23:14:26.781754",
          "status": "completed"
        },
        "tags": [],
        "id": "c652a192"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, texts, targets):\n",
        "        self.texts = texts\n",
        "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        target = self.targets[idx]\n",
        "        return text, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility\n",
        "L.seed_everything(seed=252)\n",
        "\n",
        "# Create train dataset and dataloader\n",
        "train_dataset = CustomDataset(\n",
        "    texts=train['text'].values.tolist(),\n",
        "    targets=train['target'].values.tolist()\n",
        ")\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "# Create test dataset and dataloader\n",
        "test_dataset = CustomDataset(\n",
        "    texts=test['text'].values.tolist(),\n",
        "    targets=test['target'].values.tolist()\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=False,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "# Create validation dataset and dataloader\n",
        "val_dataset = CustomDataset(\n",
        "    texts=val['text'].values.tolist(),\n",
        "    targets=val['target'].values.tolist()\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=False,\n",
        "    drop_last=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLKsACAGw3b0",
        "outputId": "7bf2ace1-3322-4a0f-bd9c-3d143117232c"
      },
      "id": "tLKsACAGw3b0",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Seed set to 252\n",
            "INFO:lightning.fabric.utilities.seed:Seed set to 252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7da5c45b",
      "metadata": {
        "papermill": {
          "duration": 0.008031,
          "end_time": "2024-04-22T23:14:26.815699",
          "exception": false,
          "start_time": "2024-04-22T23:14:26.807668",
          "status": "completed"
        },
        "tags": [],
        "id": "7da5c45b"
      },
      "source": [
        "# Tokenization function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(text):\n",
        "    \"\"\"\n",
        "    Tokenize the text and return PyTorch tensors with dynamic padding\n",
        "    \"\"\"\n",
        "    encodings = tokenizer(\n",
        "        text,\n",
        "        return_tensors='pt',\n",
        "        padding='longest',  # Dynamically pad each batch to the length of the longest sequence\n",
        "        add_special_tokens=False\n",
        "    )\n",
        "\n",
        "    return encodings\n"
      ],
      "metadata": {
        "id": "YRMQboHnJ7gJ"
      },
      "id": "YRMQboHnJ7gJ",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a2a03f3a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T17:22:30.925403Z",
          "iopub.status.busy": "2024-04-22T17:22:30.924941Z",
          "iopub.status.idle": "2024-04-22T17:22:30.933174Z",
          "shell.execute_reply": "2024-04-22T17:22:30.932089Z",
          "shell.execute_reply.started": "2024-04-22T17:22:30.925363Z"
        },
        "papermill": {
          "duration": 0.00841,
          "end_time": "2024-04-22T23:14:26.857109",
          "exception": false,
          "start_time": "2024-04-22T23:14:26.848699",
          "status": "completed"
        },
        "tags": [],
        "id": "a2a03f3a"
      },
      "source": [
        "# Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2aa40aea",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T23:14:26.875515Z",
          "iopub.status.busy": "2024-04-22T23:14:26.874796Z",
          "iopub.status.idle": "2024-04-22T23:14:26.883751Z",
          "shell.execute_reply": "2024-04-22T23:14:26.883062Z"
        },
        "papermill": {
          "duration": 0.020179,
          "end_time": "2024-04-22T23:14:26.885633",
          "exception": false,
          "start_time": "2024-04-22T23:14:26.865454",
          "status": "completed"
        },
        "tags": [],
        "id": "2aa40aea"
      },
      "outputs": [],
      "source": [
        "def disable_dropout(model: torch.nn.Module):\n",
        "    \"\"\"Disable dropout in a model.\"\"\"\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, torch.nn.Dropout):\n",
        "            module.p = 0\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Get LLM configuration\n",
        "        config = AutoConfig.from_pretrained(model_id)\n",
        "\n",
        "        # LoRA config\n",
        "        peft_config = LoraConfig(\n",
        "            task_type=TaskType.CAUSAL_LM,\n",
        "            inference_mode=False,\n",
        "            r=8,\n",
        "            lora_alpha=16,\n",
        "            target_modules='all-linear',\n",
        "            lora_dropout=0.\n",
        "        )\n",
        "\n",
        "        # Load pre-trained language model with specific configurations\n",
        "        self.backbone = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            device_map=\"cuda\",\n",
        "            low_cpu_mem_usage=True,\n",
        "            trust_remote_code=True,\n",
        "        )\n",
        "\n",
        "        # Replace language model head with an identity function\n",
        "        self.backbone.lm_head = nn.Identity()\n",
        "\n",
        "        # Apply LoRA\n",
        "        self.backbone = get_peft_model(self.backbone, peft_config)\n",
        "        self.backbone.print_trainable_parameters()\n",
        "\n",
        "        # Define classification head\n",
        "        self.cls_head = nn.Sequential(\n",
        "            nn.Linear(config.hidden_size, 768),\n",
        "            nn.ReLU(),\n",
        "            nn.LayerNorm(768),\n",
        "            nn.Linear(768, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        x = self.backbone(input_ids, attention_mask).logits  # get last hidden state\n",
        "        logits = self.cls_head(x)[:, -1, :]  # Apply classification head to the last token's output\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7928c895",
      "metadata": {
        "papermill": {
          "duration": 0.008326,
          "end_time": "2024-04-22T23:14:26.902630",
          "exception": false,
          "start_time": "2024-04-22T23:14:26.894304",
          "status": "completed"
        },
        "tags": [],
        "id": "7928c895"
      },
      "source": [
        "# Optimizer and Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "faa1f254",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T23:14:26.920974Z",
          "iopub.status.busy": "2024-04-22T23:14:26.920665Z",
          "iopub.status.idle": "2024-04-22T23:14:26.933845Z",
          "shell.execute_reply": "2024-04-22T23:14:26.933046Z"
        },
        "papermill": {
          "duration": 0.024583,
          "end_time": "2024-04-22T23:14:26.935644",
          "exception": false,
          "start_time": "2024-04-22T23:14:26.911061",
          "status": "completed"
        },
        "tags": [],
        "id": "faa1f254"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(model, learning_rate=0.0001, diff_lr=0.00001, weight_decay=0.01):\n",
        "    \"\"\"\n",
        "    Get optimizer with different learning rates for specified layers.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The neural network model.\n",
        "        learning_rate (float): Learning rate for non-differential layers.\n",
        "        diff_lr (float): Learning rate for differential layers.\n",
        "        weight_decay (float): Weight decay (decoupled from L2 penalty) for optimizer.\n",
        "\n",
        "    Returns:\n",
        "        torch.optim.AdamW: Optimizer for the model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define parameters with different learning rates and weight decay\n",
        "    no_decay = ['bias', 'LayerNorm.weight']\n",
        "    differential_layers = ['backbone']\n",
        "\n",
        "    optimizer = torch.optim.AdamW(\n",
        "            [\n",
        "                {\n",
        "                    \"params\": [\n",
        "                        param\n",
        "                        for name, param in model.named_parameters()\n",
        "                        if (not any(layer in name for layer in differential_layers))\n",
        "                        and (not any(nd in name for nd in no_decay))\n",
        "                    ],\n",
        "                    \"lr\": learning_rate,\n",
        "                    \"weight_decay\": weight_decay,\n",
        "                },\n",
        "                {\n",
        "                    \"params\": [\n",
        "                        param\n",
        "                        for name, param in model.named_parameters()\n",
        "                        if (not any(layer in name for layer in differential_layers))\n",
        "                        and (any(nd in name for nd in no_decay))\n",
        "                    ],\n",
        "                    \"lr\": learning_rate,\n",
        "                    \"weight_decay\": 0,\n",
        "                },\n",
        "                {\n",
        "                    \"params\": [\n",
        "                        param\n",
        "                        for name, param in model.named_parameters()\n",
        "                        if (any(layer in name for layer in differential_layers))\n",
        "                        and (not any(nd in name for nd in no_decay))\n",
        "                    ],\n",
        "                    \"lr\": diff_lr,\n",
        "                    \"weight_decay\": weight_decay,\n",
        "                },\n",
        "                {\n",
        "                    \"params\": [\n",
        "                        param\n",
        "                        for name, param in model.named_parameters()\n",
        "                        if (any(layer in name for layer in differential_layers))\n",
        "                        and (any(nd in name for nd in no_decay))\n",
        "                    ],\n",
        "                    \"lr\": diff_lr,\n",
        "                    \"weight_decay\": 0,\n",
        "                },\n",
        "            ],\n",
        "            lr=learning_rate,\n",
        "            weight_decay=weight_decay,\n",
        "    )\n",
        "\n",
        "    return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45b5f796",
      "metadata": {
        "papermill": {
          "duration": 0.008311,
          "end_time": "2024-04-22T23:14:26.952420",
          "exception": false,
          "start_time": "2024-04-22T23:14:26.944109",
          "status": "completed"
        },
        "tags": [],
        "id": "45b5f796"
      },
      "source": [
        "# Hyperameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "12927cb6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T23:14:26.970958Z",
          "iopub.status.busy": "2024-04-22T23:14:26.970321Z",
          "iopub.status.idle": "2024-04-22T23:14:26.974903Z",
          "shell.execute_reply": "2024-04-22T23:14:26.974056Z"
        },
        "papermill": {
          "duration": 0.01576,
          "end_time": "2024-04-22T23:14:26.976701",
          "exception": false,
          "start_time": "2024-04-22T23:14:26.960941",
          "status": "completed"
        },
        "tags": [],
        "id": "12927cb6"
      },
      "outputs": [],
      "source": [
        "num_epochs = 2\n",
        "learning_rate = 0.0002\n",
        "diff_lr = 0.00001\n",
        "warmup_steps = 0\n",
        "seed = 252\n",
        "weight_decay = 0.01\n",
        "acc_steps = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e96c270",
      "metadata": {
        "papermill": {
          "duration": 0.008328,
          "end_time": "2024-04-22T23:14:27.017463",
          "exception": false,
          "start_time": "2024-04-22T23:14:27.009135",
          "status": "completed"
        },
        "tags": [],
        "id": "8e96c270"
      },
      "source": [
        "# Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using device: {device}')"
      ],
      "metadata": {
        "id": "P3P8mxxg0bLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b366f14-51bf-4bb0-98af-4b79cba22a93"
      },
      "id": "P3P8mxxg0bLM",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "63bb4bb0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-22T23:14:27.035820Z",
          "iopub.status.busy": "2024-04-22T23:14:27.035559Z",
          "iopub.status.idle": "2024-04-23T03:56:08.292048Z",
          "shell.execute_reply": "2024-04-23T03:56:08.290997Z"
        },
        "papermill": {
          "duration": 16901.267986,
          "end_time": "2024-04-23T03:56:08.294020",
          "exception": false,
          "start_time": "2024-04-22T23:14:27.026034",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63bb4bb0",
        "outputId": "5c0680d4-a65b-44f8-c18a-c116e55cb3a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Seed set to 252\n",
            "INFO:lightning.fabric.utilities.seed:Seed set to 252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 8,650,752 || all params: 1,757,932,032 || trainable%: 0.49209820644533314\n",
            "Here are the trainable parameters:\n",
            "backbone.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight\n",
            "backbone.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight\n",
            "backbone.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight\n",
            "cls_head.0.weight\n",
            "cls_head.0.bias\n",
            "cls_head.2.weight\n",
            "cls_head.2.bias\n",
            "cls_head.3.weight\n",
            "cls_head.3.bias\n"
          ]
        }
      ],
      "source": [
        "# Set seed for reproducibility\n",
        "L.seed_everything(seed=seed)\n",
        "\n",
        "# Instantiate the neural network model\n",
        "model = Net()\n",
        "model.to(device)  # Move model to the device\n",
        "\n",
        "# Display the names of trainable parameters\n",
        "print('Here are the trainable parameters:')\n",
        "for n, p in model.named_parameters():\n",
        "    if p.requires_grad:\n",
        "        print(n)\n",
        "\n",
        "# Get the optimizer\n",
        "optimizer = get_optimizer(\n",
        "    model,\n",
        "    learning_rate=learning_rate,\n",
        "    diff_lr=diff_lr,\n",
        "    weight_decay=weight_decay\n",
        ")\n",
        "\n",
        "# Set up the scheduler for learning rate adjustment\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=warmup_steps,\n",
        "    num_training_steps=num_epochs*len(train_dataloader)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = GradScaler()\n",
        "\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        prompt, targets = batch\n",
        "\n",
        "        encodings = tokenize_text(prompt)\n",
        "\n",
        "        input_ids = encodings['input_ids'].to(device)\n",
        "        attention_mask = encodings['attention_mask'].to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Perform forward pass with autocast for mixed precision training\n",
        "        with autocast():\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = F.cross_entropy(logits, targets) / acc_steps\n",
        "\n",
        "        if not batch_idx % acc_steps:\n",
        "        # Backward pass, optimization step, and learning rate adjustment\n",
        "            optimizer.zero_grad()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "\n",
        "        # Logging training progress\n",
        "        print(\n",
        "            f'Epoch: {epoch+1} / {num_epochs}'\n",
        "            f'| Batch: {batch_idx+1}/{len(train_dataloader)}'\n",
        "            f'| Loss: {loss.item():.4f}'\n",
        "        )\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = (end_time - start_time) / 60\n",
        "print(f'Total training time: {training_time:.2f} min')"
      ],
      "metadata": {
        "id": "613alv-BrAql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f253246-2305-4ad1-d844-df44664a1d42"
      },
      "id": "613alv-BrAql",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 / 2| Batch: 1/522| Loss: 0.3683\n",
            "Epoch: 1 / 2| Batch: 2/522| Loss: 0.3977\n",
            "Epoch: 1 / 2| Batch: 3/522| Loss: 0.3281\n",
            "Epoch: 1 / 2| Batch: 4/522| Loss: 0.1803\n",
            "Epoch: 1 / 2| Batch: 5/522| Loss: 0.4722\n",
            "Epoch: 1 / 2| Batch: 6/522| Loss: 0.1276\n",
            "Epoch: 1 / 2| Batch: 7/522| Loss: 0.0361\n",
            "Epoch: 1 / 2| Batch: 8/522| Loss: 0.4598\n",
            "Epoch: 1 / 2| Batch: 9/522| Loss: 0.2556\n",
            "Epoch: 1 / 2| Batch: 10/522| Loss: 0.0484\n",
            "Epoch: 1 / 2| Batch: 11/522| Loss: 0.0332\n",
            "Epoch: 1 / 2| Batch: 12/522| Loss: 0.0087\n",
            "Epoch: 1 / 2| Batch: 13/522| Loss: 0.0603\n",
            "Epoch: 1 / 2| Batch: 14/522| Loss: 0.3647\n",
            "Epoch: 1 / 2| Batch: 15/522| Loss: 0.0083\n",
            "Epoch: 1 / 2| Batch: 16/522| Loss: 0.0299\n",
            "Epoch: 1 / 2| Batch: 17/522| Loss: 0.0049\n",
            "Epoch: 1 / 2| Batch: 18/522| Loss: 0.1150\n",
            "Epoch: 1 / 2| Batch: 19/522| Loss: 0.0122\n",
            "Epoch: 1 / 2| Batch: 20/522| Loss: 0.0019\n",
            "Epoch: 1 / 2| Batch: 21/522| Loss: 0.1002\n",
            "Epoch: 1 / 2| Batch: 22/522| Loss: 0.9186\n",
            "Epoch: 1 / 2| Batch: 23/522| Loss: 0.1254\n",
            "Epoch: 1 / 2| Batch: 24/522| Loss: 0.0265\n",
            "Epoch: 1 / 2| Batch: 25/522| Loss: 0.0242\n",
            "Epoch: 1 / 2| Batch: 26/522| Loss: 1.3271\n",
            "Epoch: 1 / 2| Batch: 27/522| Loss: 0.1040\n",
            "Epoch: 1 / 2| Batch: 28/522| Loss: 0.1475\n",
            "Epoch: 1 / 2| Batch: 29/522| Loss: 0.1275\n",
            "Epoch: 1 / 2| Batch: 30/522| Loss: 0.0047\n",
            "Epoch: 1 / 2| Batch: 31/522| Loss: 0.0097\n",
            "Epoch: 1 / 2| Batch: 32/522| Loss: 0.2175\n",
            "Epoch: 1 / 2| Batch: 33/522| Loss: 0.0008\n",
            "Epoch: 1 / 2| Batch: 34/522| Loss: 0.1351\n",
            "Epoch: 1 / 2| Batch: 35/522| Loss: 0.1950\n",
            "Epoch: 1 / 2| Batch: 36/522| Loss: 0.0084\n",
            "Epoch: 1 / 2| Batch: 37/522| Loss: 0.3182\n",
            "Epoch: 1 / 2| Batch: 38/522| Loss: 0.0009\n",
            "Epoch: 1 / 2| Batch: 39/522| Loss: 0.4998\n",
            "Epoch: 1 / 2| Batch: 40/522| Loss: 0.0004\n",
            "Epoch: 1 / 2| Batch: 41/522| Loss: 0.3573\n",
            "Epoch: 1 / 2| Batch: 42/522| Loss: 1.7531\n",
            "Epoch: 1 / 2| Batch: 43/522| Loss: 0.0055\n",
            "Epoch: 1 / 2| Batch: 44/522| Loss: 2.0235\n",
            "Epoch: 1 / 2| Batch: 45/522| Loss: 0.0080\n",
            "Epoch: 1 / 2| Batch: 46/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 47/522| Loss: 1.5956\n",
            "Epoch: 1 / 2| Batch: 48/522| Loss: 0.6324\n",
            "Epoch: 1 / 2| Batch: 49/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 50/522| Loss: 0.0839\n",
            "Epoch: 1 / 2| Batch: 51/522| Loss: 0.5450\n",
            "Epoch: 1 / 2| Batch: 52/522| Loss: 1.1144\n",
            "Epoch: 1 / 2| Batch: 53/522| Loss: 1.6709\n",
            "Epoch: 1 / 2| Batch: 54/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 55/522| Loss: 0.0174\n",
            "Epoch: 1 / 2| Batch: 56/522| Loss: 0.0443\n",
            "Epoch: 1 / 2| Batch: 57/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 58/522| Loss: 0.0070\n",
            "Epoch: 1 / 2| Batch: 59/522| Loss: 0.0076\n",
            "Epoch: 1 / 2| Batch: 60/522| Loss: 0.0019\n",
            "Epoch: 1 / 2| Batch: 61/522| Loss: 0.1864\n",
            "Epoch: 1 / 2| Batch: 62/522| Loss: 0.7664\n",
            "Epoch: 1 / 2| Batch: 63/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 64/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 65/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 66/522| Loss: 0.0132\n",
            "Epoch: 1 / 2| Batch: 67/522| Loss: 0.0036\n",
            "Epoch: 1 / 2| Batch: 68/522| Loss: 0.0843\n",
            "Epoch: 1 / 2| Batch: 69/522| Loss: 0.1359\n",
            "Epoch: 1 / 2| Batch: 70/522| Loss: 0.0897\n",
            "Epoch: 1 / 2| Batch: 71/522| Loss: 0.0729\n",
            "Epoch: 1 / 2| Batch: 72/522| Loss: 0.0010\n",
            "Epoch: 1 / 2| Batch: 73/522| Loss: 0.0170\n",
            "Epoch: 1 / 2| Batch: 74/522| Loss: 0.0493\n",
            "Epoch: 1 / 2| Batch: 75/522| Loss: 0.0004\n",
            "Epoch: 1 / 2| Batch: 76/522| Loss: 0.0022\n",
            "Epoch: 1 / 2| Batch: 77/522| Loss: 0.0136\n",
            "Epoch: 1 / 2| Batch: 78/522| Loss: 0.6428\n",
            "Epoch: 1 / 2| Batch: 79/522| Loss: 0.0015\n",
            "Epoch: 1 / 2| Batch: 80/522| Loss: 0.0256\n",
            "Epoch: 1 / 2| Batch: 81/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 82/522| Loss: 0.0030\n",
            "Epoch: 1 / 2| Batch: 83/522| Loss: 0.0014\n",
            "Epoch: 1 / 2| Batch: 84/522| Loss: 0.0115\n",
            "Epoch: 1 / 2| Batch: 85/522| Loss: 0.0023\n",
            "Epoch: 1 / 2| Batch: 86/522| Loss: 0.0419\n",
            "Epoch: 1 / 2| Batch: 87/522| Loss: 0.7501\n",
            "Epoch: 1 / 2| Batch: 88/522| Loss: 0.0007\n",
            "Epoch: 1 / 2| Batch: 89/522| Loss: 0.0044\n",
            "Epoch: 1 / 2| Batch: 90/522| Loss: 0.0325\n",
            "Epoch: 1 / 2| Batch: 91/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 92/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 93/522| Loss: 0.0009\n",
            "Epoch: 1 / 2| Batch: 94/522| Loss: 0.0247\n",
            "Epoch: 1 / 2| Batch: 95/522| Loss: 0.0041\n",
            "Epoch: 1 / 2| Batch: 96/522| Loss: 0.0694\n",
            "Epoch: 1 / 2| Batch: 97/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 98/522| Loss: 0.0036\n",
            "Epoch: 1 / 2| Batch: 99/522| Loss: 0.0084\n",
            "Epoch: 1 / 2| Batch: 100/522| Loss: 0.0013\n",
            "Epoch: 1 / 2| Batch: 101/522| Loss: 0.0410\n",
            "Epoch: 1 / 2| Batch: 102/522| Loss: 0.0004\n",
            "Epoch: 1 / 2| Batch: 103/522| Loss: 0.0008\n",
            "Epoch: 1 / 2| Batch: 104/522| Loss: 0.2438\n",
            "Epoch: 1 / 2| Batch: 105/522| Loss: 1.1576\n",
            "Epoch: 1 / 2| Batch: 106/522| Loss: 0.0029\n",
            "Epoch: 1 / 2| Batch: 107/522| Loss: 0.0003\n",
            "Epoch: 1 / 2| Batch: 108/522| Loss: 0.0108\n",
            "Epoch: 1 / 2| Batch: 109/522| Loss: 0.0003\n",
            "Epoch: 1 / 2| Batch: 110/522| Loss: 0.0003\n",
            "Epoch: 1 / 2| Batch: 111/522| Loss: 0.0081\n",
            "Epoch: 1 / 2| Batch: 112/522| Loss: 0.6213\n",
            "Epoch: 1 / 2| Batch: 113/522| Loss: 0.0009\n",
            "Epoch: 1 / 2| Batch: 114/522| Loss: 0.0017\n",
            "Epoch: 1 / 2| Batch: 115/522| Loss: 0.2662\n",
            "Epoch: 1 / 2| Batch: 116/522| Loss: 0.0006\n",
            "Epoch: 1 / 2| Batch: 117/522| Loss: 0.0081\n",
            "Epoch: 1 / 2| Batch: 118/522| Loss: 0.0570\n",
            "Epoch: 1 / 2| Batch: 119/522| Loss: 0.0006\n",
            "Epoch: 1 / 2| Batch: 120/522| Loss: 0.3221\n",
            "Epoch: 1 / 2| Batch: 121/522| Loss: 0.0045\n",
            "Epoch: 1 / 2| Batch: 122/522| Loss: 0.2129\n",
            "Epoch: 1 / 2| Batch: 123/522| Loss: 0.0005\n",
            "Epoch: 1 / 2| Batch: 124/522| Loss: 0.0023\n",
            "Epoch: 1 / 2| Batch: 125/522| Loss: 0.0897\n",
            "Epoch: 1 / 2| Batch: 126/522| Loss: 0.0278\n",
            "Epoch: 1 / 2| Batch: 127/522| Loss: 0.0072\n",
            "Epoch: 1 / 2| Batch: 128/522| Loss: 0.4370\n",
            "Epoch: 1 / 2| Batch: 129/522| Loss: 0.3444\n",
            "Epoch: 1 / 2| Batch: 130/522| Loss: 0.1334\n",
            "Epoch: 1 / 2| Batch: 131/522| Loss: 0.0007\n",
            "Epoch: 1 / 2| Batch: 132/522| Loss: 0.0048\n",
            "Epoch: 1 / 2| Batch: 133/522| Loss: 0.0011\n",
            "Epoch: 1 / 2| Batch: 134/522| Loss: 0.0016\n",
            "Epoch: 1 / 2| Batch: 135/522| Loss: 0.0072\n",
            "Epoch: 1 / 2| Batch: 136/522| Loss: 0.0131\n",
            "Epoch: 1 / 2| Batch: 137/522| Loss: 0.0338\n",
            "Epoch: 1 / 2| Batch: 138/522| Loss: 0.0005\n",
            "Epoch: 1 / 2| Batch: 139/522| Loss: 0.0700\n",
            "Epoch: 1 / 2| Batch: 140/522| Loss: 1.2516\n",
            "Epoch: 1 / 2| Batch: 141/522| Loss: 0.0081\n",
            "Epoch: 1 / 2| Batch: 142/522| Loss: 0.1668\n",
            "Epoch: 1 / 2| Batch: 143/522| Loss: 0.0019\n",
            "Epoch: 1 / 2| Batch: 144/522| Loss: 0.0010\n",
            "Epoch: 1 / 2| Batch: 145/522| Loss: 0.1440\n",
            "Epoch: 1 / 2| Batch: 146/522| Loss: 0.0730\n",
            "Epoch: 1 / 2| Batch: 147/522| Loss: 0.0187\n",
            "Epoch: 1 / 2| Batch: 148/522| Loss: 0.0557\n",
            "Epoch: 1 / 2| Batch: 149/522| Loss: 0.0054\n",
            "Epoch: 1 / 2| Batch: 150/522| Loss: 0.0117\n",
            "Epoch: 1 / 2| Batch: 151/522| Loss: 0.3863\n",
            "Epoch: 1 / 2| Batch: 152/522| Loss: 0.0092\n",
            "Epoch: 1 / 2| Batch: 153/522| Loss: 0.0171\n",
            "Epoch: 1 / 2| Batch: 154/522| Loss: 0.0137\n",
            "Epoch: 1 / 2| Batch: 155/522| Loss: 0.0049\n",
            "Epoch: 1 / 2| Batch: 156/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 157/522| Loss: 0.0005\n",
            "Epoch: 1 / 2| Batch: 158/522| Loss: 0.0079\n",
            "Epoch: 1 / 2| Batch: 159/522| Loss: 0.0040\n",
            "Epoch: 1 / 2| Batch: 160/522| Loss: 0.0011\n",
            "Epoch: 1 / 2| Batch: 161/522| Loss: 0.0013\n",
            "Epoch: 1 / 2| Batch: 162/522| Loss: 0.0052\n",
            "Epoch: 1 / 2| Batch: 163/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 164/522| Loss: 0.0134\n",
            "Epoch: 1 / 2| Batch: 165/522| Loss: 0.0017\n",
            "Epoch: 1 / 2| Batch: 166/522| Loss: 0.0251\n",
            "Epoch: 1 / 2| Batch: 167/522| Loss: 0.0010\n",
            "Epoch: 1 / 2| Batch: 168/522| Loss: 0.0005\n",
            "Epoch: 1 / 2| Batch: 169/522| Loss: 0.0040\n",
            "Epoch: 1 / 2| Batch: 170/522| Loss: 0.2201\n",
            "Epoch: 1 / 2| Batch: 171/522| Loss: 0.1477\n",
            "Epoch: 1 / 2| Batch: 172/522| Loss: 0.0048\n",
            "Epoch: 1 / 2| Batch: 173/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 174/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 175/522| Loss: 0.0170\n",
            "Epoch: 1 / 2| Batch: 176/522| Loss: 0.0068\n",
            "Epoch: 1 / 2| Batch: 177/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 178/522| Loss: 0.0007\n",
            "Epoch: 1 / 2| Batch: 179/522| Loss: 0.0504\n",
            "Epoch: 1 / 2| Batch: 180/522| Loss: 0.0023\n",
            "Epoch: 1 / 2| Batch: 181/522| Loss: 0.5718\n",
            "Epoch: 1 / 2| Batch: 182/522| Loss: 0.0033\n",
            "Epoch: 1 / 2| Batch: 183/522| Loss: 0.0009\n",
            "Epoch: 1 / 2| Batch: 184/522| Loss: 0.0596\n",
            "Epoch: 1 / 2| Batch: 185/522| Loss: 0.0004\n",
            "Epoch: 1 / 2| Batch: 186/522| Loss: 0.0003\n",
            "Epoch: 1 / 2| Batch: 187/522| Loss: 0.0035\n",
            "Epoch: 1 / 2| Batch: 188/522| Loss: 0.0404\n",
            "Epoch: 1 / 2| Batch: 189/522| Loss: 0.0024\n",
            "Epoch: 1 / 2| Batch: 190/522| Loss: 0.0010\n",
            "Epoch: 1 / 2| Batch: 191/522| Loss: 0.0047\n",
            "Epoch: 1 / 2| Batch: 192/522| Loss: 0.0410\n",
            "Epoch: 1 / 2| Batch: 193/522| Loss: 0.0080\n",
            "Epoch: 1 / 2| Batch: 194/522| Loss: 0.0954\n",
            "Epoch: 1 / 2| Batch: 195/522| Loss: 0.0013\n",
            "Epoch: 1 / 2| Batch: 196/522| Loss: 0.0058\n",
            "Epoch: 1 / 2| Batch: 197/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 198/522| Loss: 0.0003\n",
            "Epoch: 1 / 2| Batch: 199/522| Loss: 0.0233\n",
            "Epoch: 1 / 2| Batch: 200/522| Loss: 0.0266\n",
            "Epoch: 1 / 2| Batch: 201/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 202/522| Loss: 0.0009\n",
            "Epoch: 1 / 2| Batch: 203/522| Loss: 0.0020\n",
            "Epoch: 1 / 2| Batch: 204/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 205/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 206/522| Loss: 0.0048\n",
            "Epoch: 1 / 2| Batch: 207/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 208/522| Loss: 0.0040\n",
            "Epoch: 1 / 2| Batch: 209/522| Loss: 0.1108\n",
            "Epoch: 1 / 2| Batch: 210/522| Loss: 0.0202\n",
            "Epoch: 1 / 2| Batch: 211/522| Loss: 0.0030\n",
            "Epoch: 1 / 2| Batch: 212/522| Loss: 0.0258\n",
            "Epoch: 1 / 2| Batch: 213/522| Loss: 0.0417\n",
            "Epoch: 1 / 2| Batch: 214/522| Loss: 0.0008\n",
            "Epoch: 1 / 2| Batch: 215/522| Loss: 0.0038\n",
            "Epoch: 1 / 2| Batch: 216/522| Loss: 0.0006\n",
            "Epoch: 1 / 2| Batch: 217/522| Loss: 0.0022\n",
            "Epoch: 1 / 2| Batch: 218/522| Loss: 0.0959\n",
            "Epoch: 1 / 2| Batch: 219/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 220/522| Loss: 0.0524\n",
            "Epoch: 1 / 2| Batch: 221/522| Loss: 0.0188\n",
            "Epoch: 1 / 2| Batch: 222/522| Loss: 0.0100\n",
            "Epoch: 1 / 2| Batch: 223/522| Loss: 0.0008\n",
            "Epoch: 1 / 2| Batch: 224/522| Loss: 0.0004\n",
            "Epoch: 1 / 2| Batch: 225/522| Loss: 0.0117\n",
            "Epoch: 1 / 2| Batch: 226/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 227/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 228/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 229/522| Loss: 0.0145\n",
            "Epoch: 1 / 2| Batch: 230/522| Loss: 0.0033\n",
            "Epoch: 1 / 2| Batch: 231/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 232/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 233/522| Loss: 0.0012\n",
            "Epoch: 1 / 2| Batch: 234/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 235/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 236/522| Loss: 0.0029\n",
            "Epoch: 1 / 2| Batch: 237/522| Loss: 0.0082\n",
            "Epoch: 1 / 2| Batch: 238/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 239/522| Loss: 0.0824\n",
            "Epoch: 1 / 2| Batch: 240/522| Loss: 0.0025\n",
            "Epoch: 1 / 2| Batch: 241/522| Loss: 0.0012\n",
            "Epoch: 1 / 2| Batch: 242/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 243/522| Loss: 0.0007\n",
            "Epoch: 1 / 2| Batch: 244/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 245/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 246/522| Loss: 0.0054\n",
            "Epoch: 1 / 2| Batch: 247/522| Loss: 0.0017\n",
            "Epoch: 1 / 2| Batch: 248/522| Loss: 0.0006\n",
            "Epoch: 1 / 2| Batch: 249/522| Loss: 0.0122\n",
            "Epoch: 1 / 2| Batch: 250/522| Loss: 0.0026\n",
            "Epoch: 1 / 2| Batch: 251/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 252/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 253/522| Loss: 0.0010\n",
            "Epoch: 1 / 2| Batch: 254/522| Loss: 0.0004\n",
            "Epoch: 1 / 2| Batch: 255/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 256/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 257/522| Loss: 0.0005\n",
            "Epoch: 1 / 2| Batch: 258/522| Loss: 0.0004\n",
            "Epoch: 1 / 2| Batch: 259/522| Loss: 0.0016\n",
            "Epoch: 1 / 2| Batch: 260/522| Loss: 0.0012\n",
            "Epoch: 1 / 2| Batch: 261/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 262/522| Loss: 0.0014\n",
            "Epoch: 1 / 2| Batch: 263/522| Loss: 0.0007\n",
            "Epoch: 1 / 2| Batch: 264/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 265/522| Loss: 0.0011\n",
            "Epoch: 1 / 2| Batch: 266/522| Loss: 0.0008\n",
            "Epoch: 1 / 2| Batch: 267/522| Loss: 0.0013\n",
            "Epoch: 1 / 2| Batch: 268/522| Loss: 0.1114\n",
            "Epoch: 1 / 2| Batch: 269/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 270/522| Loss: 0.0512\n",
            "Epoch: 1 / 2| Batch: 271/522| Loss: 0.0074\n",
            "Epoch: 1 / 2| Batch: 272/522| Loss: 0.0013\n",
            "Epoch: 1 / 2| Batch: 273/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 274/522| Loss: 0.0512\n",
            "Epoch: 1 / 2| Batch: 275/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 276/522| Loss: 0.0005\n",
            "Epoch: 1 / 2| Batch: 277/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 278/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 279/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 280/522| Loss: 0.1230\n",
            "Epoch: 1 / 2| Batch: 281/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 282/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 283/522| Loss: 0.0010\n",
            "Epoch: 1 / 2| Batch: 284/522| Loss: 0.0014\n",
            "Epoch: 1 / 2| Batch: 285/522| Loss: 0.0076\n",
            "Epoch: 1 / 2| Batch: 286/522| Loss: 0.0112\n",
            "Epoch: 1 / 2| Batch: 287/522| Loss: 0.0024\n",
            "Epoch: 1 / 2| Batch: 288/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 289/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 290/522| Loss: 0.0012\n",
            "Epoch: 1 / 2| Batch: 291/522| Loss: 0.0019\n",
            "Epoch: 1 / 2| Batch: 292/522| Loss: 0.0017\n",
            "Epoch: 1 / 2| Batch: 293/522| Loss: 0.0019\n",
            "Epoch: 1 / 2| Batch: 294/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 295/522| Loss: 0.0003\n",
            "Epoch: 1 / 2| Batch: 296/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 297/522| Loss: 0.4525\n",
            "Epoch: 1 / 2| Batch: 298/522| Loss: 0.7632\n",
            "Epoch: 1 / 2| Batch: 299/522| Loss: 0.0003\n",
            "Epoch: 1 / 2| Batch: 300/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 301/522| Loss: 0.0009\n",
            "Epoch: 1 / 2| Batch: 302/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 303/522| Loss: 0.0044\n",
            "Epoch: 1 / 2| Batch: 304/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 305/522| Loss: 0.0003\n",
            "Epoch: 1 / 2| Batch: 306/522| Loss: 0.0004\n",
            "Epoch: 1 / 2| Batch: 307/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 308/522| Loss: 0.0008\n",
            "Epoch: 1 / 2| Batch: 309/522| Loss: 0.0082\n",
            "Epoch: 1 / 2| Batch: 310/522| Loss: 0.0047\n",
            "Epoch: 1 / 2| Batch: 311/522| Loss: 0.0131\n",
            "Epoch: 1 / 2| Batch: 312/522| Loss: 0.0008\n",
            "Epoch: 1 / 2| Batch: 313/522| Loss: 0.0963\n",
            "Epoch: 1 / 2| Batch: 314/522| Loss: 0.0950\n",
            "Epoch: 1 / 2| Batch: 315/522| Loss: 0.4812\n",
            "Epoch: 1 / 2| Batch: 316/522| Loss: 0.0029\n",
            "Epoch: 1 / 2| Batch: 317/522| Loss: 0.0031\n",
            "Epoch: 1 / 2| Batch: 318/522| Loss: 1.7376\n",
            "Epoch: 1 / 2| Batch: 319/522| Loss: 0.0563\n",
            "Epoch: 1 / 2| Batch: 320/522| Loss: 0.0007\n",
            "Epoch: 1 / 2| Batch: 321/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 322/522| Loss: 0.1842\n",
            "Epoch: 1 / 2| Batch: 323/522| Loss: 0.0014\n",
            "Epoch: 1 / 2| Batch: 324/522| Loss: 0.0015\n",
            "Epoch: 1 / 2| Batch: 325/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 326/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 327/522| Loss: 0.0004\n",
            "Epoch: 1 / 2| Batch: 328/522| Loss: 0.0131\n",
            "Epoch: 1 / 2| Batch: 329/522| Loss: 0.0307\n",
            "Epoch: 1 / 2| Batch: 330/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 331/522| Loss: 0.0035\n",
            "Epoch: 1 / 2| Batch: 332/522| Loss: 0.0094\n",
            "Epoch: 1 / 2| Batch: 333/522| Loss: 0.0014\n",
            "Epoch: 1 / 2| Batch: 334/522| Loss: 0.0042\n",
            "Epoch: 1 / 2| Batch: 335/522| Loss: 0.0009\n",
            "Epoch: 1 / 2| Batch: 336/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 337/522| Loss: 0.0003\n",
            "Epoch: 1 / 2| Batch: 338/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 339/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 340/522| Loss: 0.1162\n",
            "Epoch: 1 / 2| Batch: 341/522| Loss: 0.0065\n",
            "Epoch: 1 / 2| Batch: 342/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 343/522| Loss: 0.0073\n",
            "Epoch: 1 / 2| Batch: 344/522| Loss: 0.0075\n",
            "Epoch: 1 / 2| Batch: 345/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 346/522| Loss: 0.0044\n",
            "Epoch: 1 / 2| Batch: 347/522| Loss: 0.0052\n",
            "Epoch: 1 / 2| Batch: 348/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 349/522| Loss: 0.0059\n",
            "Epoch: 1 / 2| Batch: 350/522| Loss: 0.0019\n",
            "Epoch: 1 / 2| Batch: 351/522| Loss: 0.0069\n",
            "Epoch: 1 / 2| Batch: 352/522| Loss: 0.0007\n",
            "Epoch: 1 / 2| Batch: 353/522| Loss: 1.1534\n",
            "Epoch: 1 / 2| Batch: 354/522| Loss: 0.1492\n",
            "Epoch: 1 / 2| Batch: 355/522| Loss: 0.5547\n",
            "Epoch: 1 / 2| Batch: 356/522| Loss: 0.0066\n",
            "Epoch: 1 / 2| Batch: 357/522| Loss: 0.0003\n",
            "Epoch: 1 / 2| Batch: 358/522| Loss: 0.0016\n",
            "Epoch: 1 / 2| Batch: 359/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 360/522| Loss: 0.0114\n",
            "Epoch: 1 / 2| Batch: 361/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 362/522| Loss: 0.0048\n",
            "Epoch: 1 / 2| Batch: 363/522| Loss: 0.1439\n",
            "Epoch: 1 / 2| Batch: 364/522| Loss: 0.6307\n",
            "Epoch: 1 / 2| Batch: 365/522| Loss: 0.1031\n",
            "Epoch: 1 / 2| Batch: 366/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 367/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 368/522| Loss: 0.0005\n",
            "Epoch: 1 / 2| Batch: 369/522| Loss: 0.0008\n",
            "Epoch: 1 / 2| Batch: 370/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 371/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 372/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 373/522| Loss: 0.0864\n",
            "Epoch: 1 / 2| Batch: 374/522| Loss: 0.0020\n",
            "Epoch: 1 / 2| Batch: 375/522| Loss: 0.0093\n",
            "Epoch: 1 / 2| Batch: 376/522| Loss: 0.6524\n",
            "Epoch: 1 / 2| Batch: 377/522| Loss: 0.0007\n",
            "Epoch: 1 / 2| Batch: 378/522| Loss: 0.0461\n",
            "Epoch: 1 / 2| Batch: 379/522| Loss: 0.0008\n",
            "Epoch: 1 / 2| Batch: 380/522| Loss: 0.0057\n",
            "Epoch: 1 / 2| Batch: 381/522| Loss: 0.0003\n",
            "Epoch: 1 / 2| Batch: 382/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 383/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 384/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 385/522| Loss: 0.0004\n",
            "Epoch: 1 / 2| Batch: 386/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 387/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 388/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 389/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 390/522| Loss: 0.0101\n",
            "Epoch: 1 / 2| Batch: 391/522| Loss: 0.0991\n",
            "Epoch: 1 / 2| Batch: 392/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 393/522| Loss: 0.0074\n",
            "Epoch: 1 / 2| Batch: 394/522| Loss: 0.0132\n",
            "Epoch: 1 / 2| Batch: 395/522| Loss: 0.1143\n",
            "Epoch: 1 / 2| Batch: 396/522| Loss: 1.3282\n",
            "Epoch: 1 / 2| Batch: 397/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 398/522| Loss: 0.0075\n",
            "Epoch: 1 / 2| Batch: 399/522| Loss: 0.0058\n",
            "Epoch: 1 / 2| Batch: 400/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 401/522| Loss: 0.0013\n",
            "Epoch: 1 / 2| Batch: 402/522| Loss: 0.0366\n",
            "Epoch: 1 / 2| Batch: 403/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 404/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 405/522| Loss: 0.0134\n",
            "Epoch: 1 / 2| Batch: 406/522| Loss: 0.0009\n",
            "Epoch: 1 / 2| Batch: 407/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 408/522| Loss: 1.7178\n",
            "Epoch: 1 / 2| Batch: 409/522| Loss: 0.0026\n",
            "Epoch: 1 / 2| Batch: 410/522| Loss: 0.2511\n",
            "Epoch: 1 / 2| Batch: 411/522| Loss: 1.0674\n",
            "Epoch: 1 / 2| Batch: 412/522| Loss: 0.0472\n",
            "Epoch: 1 / 2| Batch: 413/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 414/522| Loss: 0.0194\n",
            "Epoch: 1 / 2| Batch: 415/522| Loss: 1.2022\n",
            "Epoch: 1 / 2| Batch: 416/522| Loss: 0.0014\n",
            "Epoch: 1 / 2| Batch: 417/522| Loss: 0.0024\n",
            "Epoch: 1 / 2| Batch: 418/522| Loss: 0.0365\n",
            "Epoch: 1 / 2| Batch: 419/522| Loss: 0.0003\n",
            "Epoch: 1 / 2| Batch: 420/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 421/522| Loss: 0.0023\n",
            "Epoch: 1 / 2| Batch: 422/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 423/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 424/522| Loss: 0.0004\n",
            "Epoch: 1 / 2| Batch: 425/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 426/522| Loss: 0.0004\n",
            "Epoch: 1 / 2| Batch: 427/522| Loss: 0.0185\n",
            "Epoch: 1 / 2| Batch: 428/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 429/522| Loss: 0.0016\n",
            "Epoch: 1 / 2| Batch: 430/522| Loss: 0.0003\n",
            "Epoch: 1 / 2| Batch: 431/522| Loss: 0.1266\n",
            "Epoch: 1 / 2| Batch: 432/522| Loss: 0.0014\n",
            "Epoch: 1 / 2| Batch: 433/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 434/522| Loss: 0.0003\n",
            "Epoch: 1 / 2| Batch: 435/522| Loss: 0.0014\n",
            "Epoch: 1 / 2| Batch: 436/522| Loss: 0.0022\n",
            "Epoch: 1 / 2| Batch: 437/522| Loss: 0.0249\n",
            "Epoch: 1 / 2| Batch: 438/522| Loss: 0.0030\n",
            "Epoch: 1 / 2| Batch: 439/522| Loss: 0.0030\n",
            "Epoch: 1 / 2| Batch: 440/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 441/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 442/522| Loss: 0.0013\n",
            "Epoch: 1 / 2| Batch: 443/522| Loss: 0.0003\n",
            "Epoch: 1 / 2| Batch: 444/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 445/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 446/522| Loss: 0.0653\n",
            "Epoch: 1 / 2| Batch: 447/522| Loss: 0.0009\n",
            "Epoch: 1 / 2| Batch: 448/522| Loss: 0.0030\n",
            "Epoch: 1 / 2| Batch: 449/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 450/522| Loss: 0.0927\n",
            "Epoch: 1 / 2| Batch: 451/522| Loss: 0.1144\n",
            "Epoch: 1 / 2| Batch: 452/522| Loss: 0.0004\n",
            "Epoch: 1 / 2| Batch: 453/522| Loss: 0.0008\n",
            "Epoch: 1 / 2| Batch: 454/522| Loss: 0.0004\n",
            "Epoch: 1 / 2| Batch: 455/522| Loss: 0.0012\n",
            "Epoch: 1 / 2| Batch: 456/522| Loss: 0.0210\n",
            "Epoch: 1 / 2| Batch: 457/522| Loss: 0.0006\n",
            "Epoch: 1 / 2| Batch: 458/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 459/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 460/522| Loss: 0.1564\n",
            "Epoch: 1 / 2| Batch: 461/522| Loss: 0.0004\n",
            "Epoch: 1 / 2| Batch: 462/522| Loss: 0.0092\n",
            "Epoch: 1 / 2| Batch: 463/522| Loss: 0.0005\n",
            "Epoch: 1 / 2| Batch: 464/522| Loss: 0.0162\n",
            "Epoch: 1 / 2| Batch: 465/522| Loss: 0.0032\n",
            "Epoch: 1 / 2| Batch: 466/522| Loss: 0.0003\n",
            "Epoch: 1 / 2| Batch: 467/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 468/522| Loss: 0.0012\n",
            "Epoch: 1 / 2| Batch: 469/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 470/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 471/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 472/522| Loss: 0.0117\n",
            "Epoch: 1 / 2| Batch: 473/522| Loss: 0.0019\n",
            "Epoch: 1 / 2| Batch: 474/522| Loss: 0.0075\n",
            "Epoch: 1 / 2| Batch: 475/522| Loss: 0.1240\n",
            "Epoch: 1 / 2| Batch: 476/522| Loss: 0.0007\n",
            "Epoch: 1 / 2| Batch: 477/522| Loss: 0.0008\n",
            "Epoch: 1 / 2| Batch: 478/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 479/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 480/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 481/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 482/522| Loss: 0.0009\n",
            "Epoch: 1 / 2| Batch: 483/522| Loss: 0.0015\n",
            "Epoch: 1 / 2| Batch: 484/522| Loss: 0.0008\n",
            "Epoch: 1 / 2| Batch: 485/522| Loss: 0.0003\n",
            "Epoch: 1 / 2| Batch: 486/522| Loss: 0.0007\n",
            "Epoch: 1 / 2| Batch: 487/522| Loss: 0.0010\n",
            "Epoch: 1 / 2| Batch: 488/522| Loss: 0.0047\n",
            "Epoch: 1 / 2| Batch: 489/522| Loss: 0.0008\n",
            "Epoch: 1 / 2| Batch: 490/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 491/522| Loss: 0.0005\n",
            "Epoch: 1 / 2| Batch: 492/522| Loss: 0.0229\n",
            "Epoch: 1 / 2| Batch: 493/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 494/522| Loss: 0.7625\n",
            "Epoch: 1 / 2| Batch: 495/522| Loss: 0.0003\n",
            "Epoch: 1 / 2| Batch: 496/522| Loss: 0.0127\n",
            "Epoch: 1 / 2| Batch: 497/522| Loss: 0.0071\n",
            "Epoch: 1 / 2| Batch: 498/522| Loss: 0.0014\n",
            "Epoch: 1 / 2| Batch: 499/522| Loss: 0.0020\n",
            "Epoch: 1 / 2| Batch: 500/522| Loss: 1.1605\n",
            "Epoch: 1 / 2| Batch: 501/522| Loss: 0.0012\n",
            "Epoch: 1 / 2| Batch: 502/522| Loss: 0.1103\n",
            "Epoch: 1 / 2| Batch: 503/522| Loss: 0.0066\n",
            "Epoch: 1 / 2| Batch: 504/522| Loss: 1.3167\n",
            "Epoch: 1 / 2| Batch: 505/522| Loss: 0.6823\n",
            "Epoch: 1 / 2| Batch: 506/522| Loss: 0.3379\n",
            "Epoch: 1 / 2| Batch: 507/522| Loss: 0.0007\n",
            "Epoch: 1 / 2| Batch: 508/522| Loss: 0.0005\n",
            "Epoch: 1 / 2| Batch: 509/522| Loss: 0.0004\n",
            "Epoch: 1 / 2| Batch: 510/522| Loss: 0.0012\n",
            "Epoch: 1 / 2| Batch: 511/522| Loss: 0.0000\n",
            "Epoch: 1 / 2| Batch: 512/522| Loss: 0.0002\n",
            "Epoch: 1 / 2| Batch: 513/522| Loss: 0.0014\n",
            "Epoch: 1 / 2| Batch: 514/522| Loss: 0.0141\n",
            "Epoch: 1 / 2| Batch: 515/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 516/522| Loss: 0.0711\n",
            "Epoch: 1 / 2| Batch: 517/522| Loss: 0.0133\n",
            "Epoch: 1 / 2| Batch: 518/522| Loss: 0.0007\n",
            "Epoch: 1 / 2| Batch: 519/522| Loss: 0.2616\n",
            "Epoch: 1 / 2| Batch: 520/522| Loss: 0.0606\n",
            "Epoch: 1 / 2| Batch: 521/522| Loss: 0.0001\n",
            "Epoch: 1 / 2| Batch: 522/522| Loss: 0.0197\n",
            "Epoch: 2 / 2| Batch: 1/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 2/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 3/522| Loss: 0.0030\n",
            "Epoch: 2 / 2| Batch: 4/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 5/522| Loss: 0.0085\n",
            "Epoch: 2 / 2| Batch: 6/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 7/522| Loss: 0.0507\n",
            "Epoch: 2 / 2| Batch: 8/522| Loss: 0.1059\n",
            "Epoch: 2 / 2| Batch: 9/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 10/522| Loss: 0.0013\n",
            "Epoch: 2 / 2| Batch: 11/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 12/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 13/522| Loss: 0.0011\n",
            "Epoch: 2 / 2| Batch: 14/522| Loss: 0.0012\n",
            "Epoch: 2 / 2| Batch: 15/522| Loss: 0.0091\n",
            "Epoch: 2 / 2| Batch: 16/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 17/522| Loss: 0.0043\n",
            "Epoch: 2 / 2| Batch: 18/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 19/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 20/522| Loss: 0.0647\n",
            "Epoch: 2 / 2| Batch: 21/522| Loss: 0.0007\n",
            "Epoch: 2 / 2| Batch: 22/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 23/522| Loss: 0.0007\n",
            "Epoch: 2 / 2| Batch: 24/522| Loss: 0.0050\n",
            "Epoch: 2 / 2| Batch: 25/522| Loss: 0.0011\n",
            "Epoch: 2 / 2| Batch: 26/522| Loss: 0.0016\n",
            "Epoch: 2 / 2| Batch: 27/522| Loss: 0.0004\n",
            "Epoch: 2 / 2| Batch: 28/522| Loss: 0.0015\n",
            "Epoch: 2 / 2| Batch: 29/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 30/522| Loss: 0.0004\n",
            "Epoch: 2 / 2| Batch: 31/522| Loss: 0.0014\n",
            "Epoch: 2 / 2| Batch: 32/522| Loss: 0.0007\n",
            "Epoch: 2 / 2| Batch: 33/522| Loss: 0.8127\n",
            "Epoch: 2 / 2| Batch: 34/522| Loss: 0.0057\n",
            "Epoch: 2 / 2| Batch: 35/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 36/522| Loss: 0.0269\n",
            "Epoch: 2 / 2| Batch: 37/522| Loss: 0.0051\n",
            "Epoch: 2 / 2| Batch: 38/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 39/522| Loss: 0.9991\n",
            "Epoch: 2 / 2| Batch: 40/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 41/522| Loss: 0.0014\n",
            "Epoch: 2 / 2| Batch: 42/522| Loss: 0.0037\n",
            "Epoch: 2 / 2| Batch: 43/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 44/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 45/522| Loss: 0.0004\n",
            "Epoch: 2 / 2| Batch: 46/522| Loss: 0.0118\n",
            "Epoch: 2 / 2| Batch: 47/522| Loss: 0.0042\n",
            "Epoch: 2 / 2| Batch: 48/522| Loss: 0.1273\n",
            "Epoch: 2 / 2| Batch: 49/522| Loss: 0.1276\n",
            "Epoch: 2 / 2| Batch: 50/522| Loss: 0.0056\n",
            "Epoch: 2 / 2| Batch: 51/522| Loss: 0.0031\n",
            "Epoch: 2 / 2| Batch: 52/522| Loss: 0.0004\n",
            "Epoch: 2 / 2| Batch: 53/522| Loss: 0.0793\n",
            "Epoch: 2 / 2| Batch: 54/522| Loss: 0.0007\n",
            "Epoch: 2 / 2| Batch: 55/522| Loss: 0.0014\n",
            "Epoch: 2 / 2| Batch: 56/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 57/522| Loss: 0.0010\n",
            "Epoch: 2 / 2| Batch: 58/522| Loss: 1.0900\n",
            "Epoch: 2 / 2| Batch: 59/522| Loss: 0.0010\n",
            "Epoch: 2 / 2| Batch: 60/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 61/522| Loss: 0.0018\n",
            "Epoch: 2 / 2| Batch: 62/522| Loss: 0.0068\n",
            "Epoch: 2 / 2| Batch: 63/522| Loss: 0.0063\n",
            "Epoch: 2 / 2| Batch: 64/522| Loss: 0.4076\n",
            "Epoch: 2 / 2| Batch: 65/522| Loss: 0.0013\n",
            "Epoch: 2 / 2| Batch: 66/522| Loss: 0.0240\n",
            "Epoch: 2 / 2| Batch: 67/522| Loss: 0.0007\n",
            "Epoch: 2 / 2| Batch: 68/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 69/522| Loss: 0.0016\n",
            "Epoch: 2 / 2| Batch: 70/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 71/522| Loss: 0.0020\n",
            "Epoch: 2 / 2| Batch: 72/522| Loss: 0.0013\n",
            "Epoch: 2 / 2| Batch: 73/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 74/522| Loss: 0.0008\n",
            "Epoch: 2 / 2| Batch: 75/522| Loss: 0.0016\n",
            "Epoch: 2 / 2| Batch: 76/522| Loss: 0.0007\n",
            "Epoch: 2 / 2| Batch: 77/522| Loss: 0.0017\n",
            "Epoch: 2 / 2| Batch: 78/522| Loss: 0.0047\n",
            "Epoch: 2 / 2| Batch: 79/522| Loss: 0.0050\n",
            "Epoch: 2 / 2| Batch: 80/522| Loss: 0.0012\n",
            "Epoch: 2 / 2| Batch: 81/522| Loss: 0.0044\n",
            "Epoch: 2 / 2| Batch: 82/522| Loss: 0.0017\n",
            "Epoch: 2 / 2| Batch: 83/522| Loss: 0.0012\n",
            "Epoch: 2 / 2| Batch: 84/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 85/522| Loss: 0.0051\n",
            "Epoch: 2 / 2| Batch: 86/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 87/522| Loss: 0.0135\n",
            "Epoch: 2 / 2| Batch: 88/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 89/522| Loss: 0.0075\n",
            "Epoch: 2 / 2| Batch: 90/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 91/522| Loss: 0.0029\n",
            "Epoch: 2 / 2| Batch: 92/522| Loss: 0.0039\n",
            "Epoch: 2 / 2| Batch: 93/522| Loss: 0.0029\n",
            "Epoch: 2 / 2| Batch: 94/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 95/522| Loss: 0.0021\n",
            "Epoch: 2 / 2| Batch: 96/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 97/522| Loss: 0.0013\n",
            "Epoch: 2 / 2| Batch: 98/522| Loss: 0.0039\n",
            "Epoch: 2 / 2| Batch: 99/522| Loss: 0.0044\n",
            "Epoch: 2 / 2| Batch: 100/522| Loss: 0.0175\n",
            "Epoch: 2 / 2| Batch: 101/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 102/522| Loss: 0.0027\n",
            "Epoch: 2 / 2| Batch: 103/522| Loss: 0.0050\n",
            "Epoch: 2 / 2| Batch: 104/522| Loss: 0.0008\n",
            "Epoch: 2 / 2| Batch: 105/522| Loss: 0.0016\n",
            "Epoch: 2 / 2| Batch: 106/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 107/522| Loss: 0.0147\n",
            "Epoch: 2 / 2| Batch: 108/522| Loss: 0.0016\n",
            "Epoch: 2 / 2| Batch: 109/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 110/522| Loss: 0.0097\n",
            "Epoch: 2 / 2| Batch: 111/522| Loss: 0.0018\n",
            "Epoch: 2 / 2| Batch: 112/522| Loss: 0.0028\n",
            "Epoch: 2 / 2| Batch: 113/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 114/522| Loss: 0.0020\n",
            "Epoch: 2 / 2| Batch: 115/522| Loss: 0.0055\n",
            "Epoch: 2 / 2| Batch: 116/522| Loss: 0.0007\n",
            "Epoch: 2 / 2| Batch: 117/522| Loss: 0.0012\n",
            "Epoch: 2 / 2| Batch: 118/522| Loss: 0.0006\n",
            "Epoch: 2 / 2| Batch: 119/522| Loss: 0.0012\n",
            "Epoch: 2 / 2| Batch: 120/522| Loss: 0.0601\n",
            "Epoch: 2 / 2| Batch: 121/522| Loss: 0.0061\n",
            "Epoch: 2 / 2| Batch: 122/522| Loss: 0.0154\n",
            "Epoch: 2 / 2| Batch: 123/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 124/522| Loss: 0.0140\n",
            "Epoch: 2 / 2| Batch: 125/522| Loss: 0.0043\n",
            "Epoch: 2 / 2| Batch: 126/522| Loss: 0.0013\n",
            "Epoch: 2 / 2| Batch: 127/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 128/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 129/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 130/522| Loss: 0.0041\n",
            "Epoch: 2 / 2| Batch: 131/522| Loss: 0.0121\n",
            "Epoch: 2 / 2| Batch: 132/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 133/522| Loss: 0.0014\n",
            "Epoch: 2 / 2| Batch: 134/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 135/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 136/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 137/522| Loss: 0.0334\n",
            "Epoch: 2 / 2| Batch: 138/522| Loss: 0.0019\n",
            "Epoch: 2 / 2| Batch: 139/522| Loss: 0.0006\n",
            "Epoch: 2 / 2| Batch: 140/522| Loss: 0.0048\n",
            "Epoch: 2 / 2| Batch: 141/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 142/522| Loss: 0.0025\n",
            "Epoch: 2 / 2| Batch: 143/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 144/522| Loss: 0.0011\n",
            "Epoch: 2 / 2| Batch: 145/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 146/522| Loss: 0.0034\n",
            "Epoch: 2 / 2| Batch: 147/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 148/522| Loss: 0.0019\n",
            "Epoch: 2 / 2| Batch: 149/522| Loss: 0.0026\n",
            "Epoch: 2 / 2| Batch: 150/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 151/522| Loss: 0.0177\n",
            "Epoch: 2 / 2| Batch: 152/522| Loss: 0.0013\n",
            "Epoch: 2 / 2| Batch: 153/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 154/522| Loss: 0.0010\n",
            "Epoch: 2 / 2| Batch: 155/522| Loss: 0.0076\n",
            "Epoch: 2 / 2| Batch: 156/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 157/522| Loss: 0.0026\n",
            "Epoch: 2 / 2| Batch: 158/522| Loss: 0.0053\n",
            "Epoch: 2 / 2| Batch: 159/522| Loss: 0.8632\n",
            "Epoch: 2 / 2| Batch: 160/522| Loss: 0.0854\n",
            "Epoch: 2 / 2| Batch: 161/522| Loss: 0.0304\n",
            "Epoch: 2 / 2| Batch: 162/522| Loss: 0.0015\n",
            "Epoch: 2 / 2| Batch: 163/522| Loss: 0.0007\n",
            "Epoch: 2 / 2| Batch: 164/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 165/522| Loss: 0.0018\n",
            "Epoch: 2 / 2| Batch: 166/522| Loss: 0.0328\n",
            "Epoch: 2 / 2| Batch: 167/522| Loss: 0.0004\n",
            "Epoch: 2 / 2| Batch: 168/522| Loss: 0.3961\n",
            "Epoch: 2 / 2| Batch: 169/522| Loss: 0.0037\n",
            "Epoch: 2 / 2| Batch: 170/522| Loss: 0.0087\n",
            "Epoch: 2 / 2| Batch: 171/522| Loss: 0.0049\n",
            "Epoch: 2 / 2| Batch: 172/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 173/522| Loss: 0.0112\n",
            "Epoch: 2 / 2| Batch: 174/522| Loss: 0.0004\n",
            "Epoch: 2 / 2| Batch: 175/522| Loss: 0.0462\n",
            "Epoch: 2 / 2| Batch: 176/522| Loss: 0.0011\n",
            "Epoch: 2 / 2| Batch: 177/522| Loss: 0.0006\n",
            "Epoch: 2 / 2| Batch: 178/522| Loss: 0.0067\n",
            "Epoch: 2 / 2| Batch: 179/522| Loss: 0.0125\n",
            "Epoch: 2 / 2| Batch: 180/522| Loss: 0.0139\n",
            "Epoch: 2 / 2| Batch: 181/522| Loss: 0.0045\n",
            "Epoch: 2 / 2| Batch: 182/522| Loss: 0.0006\n",
            "Epoch: 2 / 2| Batch: 183/522| Loss: 0.0027\n",
            "Epoch: 2 / 2| Batch: 184/522| Loss: 0.0059\n",
            "Epoch: 2 / 2| Batch: 185/522| Loss: 0.0105\n",
            "Epoch: 2 / 2| Batch: 186/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 187/522| Loss: 0.0007\n",
            "Epoch: 2 / 2| Batch: 188/522| Loss: 0.0217\n",
            "Epoch: 2 / 2| Batch: 189/522| Loss: 0.0137\n",
            "Epoch: 2 / 2| Batch: 190/522| Loss: 0.0732\n",
            "Epoch: 2 / 2| Batch: 191/522| Loss: 0.0108\n",
            "Epoch: 2 / 2| Batch: 192/522| Loss: 0.0626\n",
            "Epoch: 2 / 2| Batch: 193/522| Loss: 0.0066\n",
            "Epoch: 2 / 2| Batch: 194/522| Loss: 0.0004\n",
            "Epoch: 2 / 2| Batch: 195/522| Loss: 0.0019\n",
            "Epoch: 2 / 2| Batch: 196/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 197/522| Loss: 0.0881\n",
            "Epoch: 2 / 2| Batch: 198/522| Loss: 0.0070\n",
            "Epoch: 2 / 2| Batch: 199/522| Loss: 0.4571\n",
            "Epoch: 2 / 2| Batch: 200/522| Loss: 0.0212\n",
            "Epoch: 2 / 2| Batch: 201/522| Loss: 0.0013\n",
            "Epoch: 2 / 2| Batch: 202/522| Loss: 0.0060\n",
            "Epoch: 2 / 2| Batch: 203/522| Loss: 0.0105\n",
            "Epoch: 2 / 2| Batch: 204/522| Loss: 0.1136\n",
            "Epoch: 2 / 2| Batch: 205/522| Loss: 0.0026\n",
            "Epoch: 2 / 2| Batch: 206/522| Loss: 0.0026\n",
            "Epoch: 2 / 2| Batch: 207/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 208/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 209/522| Loss: 0.0004\n",
            "Epoch: 2 / 2| Batch: 210/522| Loss: 0.0034\n",
            "Epoch: 2 / 2| Batch: 211/522| Loss: 0.0062\n",
            "Epoch: 2 / 2| Batch: 212/522| Loss: 0.0004\n",
            "Epoch: 2 / 2| Batch: 213/522| Loss: 0.0181\n",
            "Epoch: 2 / 2| Batch: 214/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 215/522| Loss: 0.0053\n",
            "Epoch: 2 / 2| Batch: 216/522| Loss: 0.0006\n",
            "Epoch: 2 / 2| Batch: 217/522| Loss: 0.0188\n",
            "Epoch: 2 / 2| Batch: 218/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 219/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 220/522| Loss: 0.0004\n",
            "Epoch: 2 / 2| Batch: 221/522| Loss: 0.0026\n",
            "Epoch: 2 / 2| Batch: 222/522| Loss: 0.0243\n",
            "Epoch: 2 / 2| Batch: 223/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 224/522| Loss: 0.0010\n",
            "Epoch: 2 / 2| Batch: 225/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 226/522| Loss: 0.0210\n",
            "Epoch: 2 / 2| Batch: 227/522| Loss: 0.0420\n",
            "Epoch: 2 / 2| Batch: 228/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 229/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 230/522| Loss: 0.1408\n",
            "Epoch: 2 / 2| Batch: 231/522| Loss: 0.0022\n",
            "Epoch: 2 / 2| Batch: 232/522| Loss: 0.0006\n",
            "Epoch: 2 / 2| Batch: 233/522| Loss: 0.0187\n",
            "Epoch: 2 / 2| Batch: 234/522| Loss: 0.0007\n",
            "Epoch: 2 / 2| Batch: 235/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 236/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 237/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 238/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 239/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 240/522| Loss: 0.1766\n",
            "Epoch: 2 / 2| Batch: 241/522| Loss: 0.0019\n",
            "Epoch: 2 / 2| Batch: 242/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 243/522| Loss: 0.0008\n",
            "Epoch: 2 / 2| Batch: 244/522| Loss: 0.0220\n",
            "Epoch: 2 / 2| Batch: 245/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 246/522| Loss: 0.0007\n",
            "Epoch: 2 / 2| Batch: 247/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 248/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 249/522| Loss: 0.0008\n",
            "Epoch: 2 / 2| Batch: 250/522| Loss: 0.0008\n",
            "Epoch: 2 / 2| Batch: 251/522| Loss: 0.2121\n",
            "Epoch: 2 / 2| Batch: 252/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 253/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 254/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 255/522| Loss: 1.0784\n",
            "Epoch: 2 / 2| Batch: 256/522| Loss: 0.0019\n",
            "Epoch: 2 / 2| Batch: 257/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 258/522| Loss: 0.0019\n",
            "Epoch: 2 / 2| Batch: 259/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 260/522| Loss: 0.0007\n",
            "Epoch: 2 / 2| Batch: 261/522| Loss: 0.0011\n",
            "Epoch: 2 / 2| Batch: 262/522| Loss: 0.0004\n",
            "Epoch: 2 / 2| Batch: 263/522| Loss: 0.0010\n",
            "Epoch: 2 / 2| Batch: 264/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 265/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 266/522| Loss: 0.0064\n",
            "Epoch: 2 / 2| Batch: 267/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 268/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 269/522| Loss: 0.0040\n",
            "Epoch: 2 / 2| Batch: 270/522| Loss: 0.0106\n",
            "Epoch: 2 / 2| Batch: 271/522| Loss: 0.0139\n",
            "Epoch: 2 / 2| Batch: 272/522| Loss: 0.1327\n",
            "Epoch: 2 / 2| Batch: 273/522| Loss: 0.0362\n",
            "Epoch: 2 / 2| Batch: 274/522| Loss: 0.0116\n",
            "Epoch: 2 / 2| Batch: 275/522| Loss: 0.0020\n",
            "Epoch: 2 / 2| Batch: 276/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 277/522| Loss: 0.0065\n",
            "Epoch: 2 / 2| Batch: 278/522| Loss: 0.0075\n",
            "Epoch: 2 / 2| Batch: 279/522| Loss: 0.0146\n",
            "Epoch: 2 / 2| Batch: 280/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 281/522| Loss: 0.0036\n",
            "Epoch: 2 / 2| Batch: 282/522| Loss: 0.0064\n",
            "Epoch: 2 / 2| Batch: 283/522| Loss: 0.0572\n",
            "Epoch: 2 / 2| Batch: 284/522| Loss: 0.0618\n",
            "Epoch: 2 / 2| Batch: 285/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 286/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 287/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 288/522| Loss: 0.0021\n",
            "Epoch: 2 / 2| Batch: 289/522| Loss: 0.0064\n",
            "Epoch: 2 / 2| Batch: 290/522| Loss: 0.0007\n",
            "Epoch: 2 / 2| Batch: 291/522| Loss: 0.0313\n",
            "Epoch: 2 / 2| Batch: 292/522| Loss: 0.0111\n",
            "Epoch: 2 / 2| Batch: 293/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 294/522| Loss: 0.0086\n",
            "Epoch: 2 / 2| Batch: 295/522| Loss: 0.0020\n",
            "Epoch: 2 / 2| Batch: 296/522| Loss: 0.0063\n",
            "Epoch: 2 / 2| Batch: 297/522| Loss: 0.0004\n",
            "Epoch: 2 / 2| Batch: 298/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 299/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 300/522| Loss: 0.0026\n",
            "Epoch: 2 / 2| Batch: 301/522| Loss: 0.0119\n",
            "Epoch: 2 / 2| Batch: 302/522| Loss: 0.0274\n",
            "Epoch: 2 / 2| Batch: 303/522| Loss: 0.0486\n",
            "Epoch: 2 / 2| Batch: 304/522| Loss: 0.0035\n",
            "Epoch: 2 / 2| Batch: 305/522| Loss: 0.0032\n",
            "Epoch: 2 / 2| Batch: 306/522| Loss: 0.0012\n",
            "Epoch: 2 / 2| Batch: 307/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 308/522| Loss: 0.0014\n",
            "Epoch: 2 / 2| Batch: 309/522| Loss: 0.0100\n",
            "Epoch: 2 / 2| Batch: 310/522| Loss: 0.0097\n",
            "Epoch: 2 / 2| Batch: 311/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 312/522| Loss: 0.0014\n",
            "Epoch: 2 / 2| Batch: 313/522| Loss: 0.0059\n",
            "Epoch: 2 / 2| Batch: 314/522| Loss: 0.0012\n",
            "Epoch: 2 / 2| Batch: 315/522| Loss: 0.0299\n",
            "Epoch: 2 / 2| Batch: 316/522| Loss: 0.0016\n",
            "Epoch: 2 / 2| Batch: 317/522| Loss: 0.2160\n",
            "Epoch: 2 / 2| Batch: 318/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 319/522| Loss: 0.0287\n",
            "Epoch: 2 / 2| Batch: 320/522| Loss: 0.0553\n",
            "Epoch: 2 / 2| Batch: 321/522| Loss: 0.0487\n",
            "Epoch: 2 / 2| Batch: 322/522| Loss: 0.0046\n",
            "Epoch: 2 / 2| Batch: 323/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 324/522| Loss: 0.0038\n",
            "Epoch: 2 / 2| Batch: 325/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 326/522| Loss: 0.1745\n",
            "Epoch: 2 / 2| Batch: 327/522| Loss: 0.0004\n",
            "Epoch: 2 / 2| Batch: 328/522| Loss: 0.0022\n",
            "Epoch: 2 / 2| Batch: 329/522| Loss: 1.0118\n",
            "Epoch: 2 / 2| Batch: 330/522| Loss: 0.0022\n",
            "Epoch: 2 / 2| Batch: 331/522| Loss: 0.0146\n",
            "Epoch: 2 / 2| Batch: 332/522| Loss: 0.1619\n",
            "Epoch: 2 / 2| Batch: 333/522| Loss: 0.0258\n",
            "Epoch: 2 / 2| Batch: 334/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 335/522| Loss: 0.0031\n",
            "Epoch: 2 / 2| Batch: 336/522| Loss: 0.0177\n",
            "Epoch: 2 / 2| Batch: 337/522| Loss: 0.0101\n",
            "Epoch: 2 / 2| Batch: 338/522| Loss: 0.0026\n",
            "Epoch: 2 / 2| Batch: 339/522| Loss: 0.0022\n",
            "Epoch: 2 / 2| Batch: 340/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 341/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 342/522| Loss: 0.0008\n",
            "Epoch: 2 / 2| Batch: 343/522| Loss: 0.0008\n",
            "Epoch: 2 / 2| Batch: 344/522| Loss: 0.0006\n",
            "Epoch: 2 / 2| Batch: 345/522| Loss: 0.0179\n",
            "Epoch: 2 / 2| Batch: 346/522| Loss: 0.0093\n",
            "Epoch: 2 / 2| Batch: 347/522| Loss: 0.1180\n",
            "Epoch: 2 / 2| Batch: 348/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 349/522| Loss: 0.0043\n",
            "Epoch: 2 / 2| Batch: 350/522| Loss: 0.0151\n",
            "Epoch: 2 / 2| Batch: 351/522| Loss: 0.0919\n",
            "Epoch: 2 / 2| Batch: 352/522| Loss: 0.0015\n",
            "Epoch: 2 / 2| Batch: 353/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 354/522| Loss: 0.0045\n",
            "Epoch: 2 / 2| Batch: 355/522| Loss: 0.0008\n",
            "Epoch: 2 / 2| Batch: 356/522| Loss: 0.0166\n",
            "Epoch: 2 / 2| Batch: 357/522| Loss: 0.0490\n",
            "Epoch: 2 / 2| Batch: 358/522| Loss: 0.0191\n",
            "Epoch: 2 / 2| Batch: 359/522| Loss: 0.0031\n",
            "Epoch: 2 / 2| Batch: 360/522| Loss: 0.0412\n",
            "Epoch: 2 / 2| Batch: 361/522| Loss: 0.0066\n",
            "Epoch: 2 / 2| Batch: 362/522| Loss: 0.0020\n",
            "Epoch: 2 / 2| Batch: 363/522| Loss: 0.0055\n",
            "Epoch: 2 / 2| Batch: 364/522| Loss: 0.0023\n",
            "Epoch: 2 / 2| Batch: 365/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 366/522| Loss: 0.0302\n",
            "Epoch: 2 / 2| Batch: 367/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 368/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 369/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 370/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 371/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 372/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 373/522| Loss: 0.0039\n",
            "Epoch: 2 / 2| Batch: 374/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 375/522| Loss: 0.0017\n",
            "Epoch: 2 / 2| Batch: 376/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 377/522| Loss: 0.0084\n",
            "Epoch: 2 / 2| Batch: 378/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 379/522| Loss: 0.0084\n",
            "Epoch: 2 / 2| Batch: 380/522| Loss: 0.0035\n",
            "Epoch: 2 / 2| Batch: 381/522| Loss: 0.0010\n",
            "Epoch: 2 / 2| Batch: 382/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 383/522| Loss: 0.0066\n",
            "Epoch: 2 / 2| Batch: 384/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 385/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 386/522| Loss: 0.0032\n",
            "Epoch: 2 / 2| Batch: 387/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 388/522| Loss: 0.0010\n",
            "Epoch: 2 / 2| Batch: 389/522| Loss: 0.0014\n",
            "Epoch: 2 / 2| Batch: 390/522| Loss: 0.0008\n",
            "Epoch: 2 / 2| Batch: 391/522| Loss: 0.0006\n",
            "Epoch: 2 / 2| Batch: 392/522| Loss: 0.0018\n",
            "Epoch: 2 / 2| Batch: 393/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 394/522| Loss: 0.0006\n",
            "Epoch: 2 / 2| Batch: 395/522| Loss: 0.0007\n",
            "Epoch: 2 / 2| Batch: 396/522| Loss: 0.0008\n",
            "Epoch: 2 / 2| Batch: 397/522| Loss: 0.0132\n",
            "Epoch: 2 / 2| Batch: 398/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 399/522| Loss: 0.0011\n",
            "Epoch: 2 / 2| Batch: 400/522| Loss: 0.0022\n",
            "Epoch: 2 / 2| Batch: 401/522| Loss: 0.0008\n",
            "Epoch: 2 / 2| Batch: 402/522| Loss: 0.0033\n",
            "Epoch: 2 / 2| Batch: 403/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 404/522| Loss: 0.0065\n",
            "Epoch: 2 / 2| Batch: 405/522| Loss: 0.2140\n",
            "Epoch: 2 / 2| Batch: 406/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 407/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 408/522| Loss: 0.0007\n",
            "Epoch: 2 / 2| Batch: 409/522| Loss: 0.0019\n",
            "Epoch: 2 / 2| Batch: 410/522| Loss: 0.0006\n",
            "Epoch: 2 / 2| Batch: 411/522| Loss: 0.0011\n",
            "Epoch: 2 / 2| Batch: 412/522| Loss: 0.0067\n",
            "Epoch: 2 / 2| Batch: 413/522| Loss: 0.0089\n",
            "Epoch: 2 / 2| Batch: 414/522| Loss: 0.0240\n",
            "Epoch: 2 / 2| Batch: 415/522| Loss: 0.0004\n",
            "Epoch: 2 / 2| Batch: 416/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 417/522| Loss: 0.0485\n",
            "Epoch: 2 / 2| Batch: 418/522| Loss: 0.0012\n",
            "Epoch: 2 / 2| Batch: 419/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 420/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 421/522| Loss: 0.0069\n",
            "Epoch: 2 / 2| Batch: 422/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 423/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 424/522| Loss: 0.0059\n",
            "Epoch: 2 / 2| Batch: 425/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 426/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 427/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 428/522| Loss: 0.0013\n",
            "Epoch: 2 / 2| Batch: 429/522| Loss: 0.0111\n",
            "Epoch: 2 / 2| Batch: 430/522| Loss: 0.0049\n",
            "Epoch: 2 / 2| Batch: 431/522| Loss: 0.0011\n",
            "Epoch: 2 / 2| Batch: 432/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 433/522| Loss: 0.0004\n",
            "Epoch: 2 / 2| Batch: 434/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 435/522| Loss: 0.0875\n",
            "Epoch: 2 / 2| Batch: 436/522| Loss: 0.0008\n",
            "Epoch: 2 / 2| Batch: 437/522| Loss: 0.0013\n",
            "Epoch: 2 / 2| Batch: 438/522| Loss: 0.0020\n",
            "Epoch: 2 / 2| Batch: 439/522| Loss: 0.0016\n",
            "Epoch: 2 / 2| Batch: 440/522| Loss: 0.0010\n",
            "Epoch: 2 / 2| Batch: 441/522| Loss: 0.0024\n",
            "Epoch: 2 / 2| Batch: 442/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 443/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 444/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 445/522| Loss: 0.0007\n",
            "Epoch: 2 / 2| Batch: 446/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 447/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 448/522| Loss: 0.0019\n",
            "Epoch: 2 / 2| Batch: 449/522| Loss: 0.0006\n",
            "Epoch: 2 / 2| Batch: 450/522| Loss: 0.0012\n",
            "Epoch: 2 / 2| Batch: 451/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 452/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 453/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 454/522| Loss: 0.0021\n",
            "Epoch: 2 / 2| Batch: 455/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 456/522| Loss: 0.0113\n",
            "Epoch: 2 / 2| Batch: 457/522| Loss: 0.0435\n",
            "Epoch: 2 / 2| Batch: 458/522| Loss: 0.0041\n",
            "Epoch: 2 / 2| Batch: 459/522| Loss: 0.0035\n",
            "Epoch: 2 / 2| Batch: 460/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 461/522| Loss: 0.0081\n",
            "Epoch: 2 / 2| Batch: 462/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 463/522| Loss: 0.1377\n",
            "Epoch: 2 / 2| Batch: 464/522| Loss: 0.0532\n",
            "Epoch: 2 / 2| Batch: 465/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 466/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 467/522| Loss: 0.0018\n",
            "Epoch: 2 / 2| Batch: 468/522| Loss: 0.0002\n",
            "Epoch: 2 / 2| Batch: 469/522| Loss: 0.0027\n",
            "Epoch: 2 / 2| Batch: 470/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 471/522| Loss: 0.0085\n",
            "Epoch: 2 / 2| Batch: 472/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 473/522| Loss: 0.0010\n",
            "Epoch: 2 / 2| Batch: 474/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 475/522| Loss: 0.3339\n",
            "Epoch: 2 / 2| Batch: 476/522| Loss: 0.0006\n",
            "Epoch: 2 / 2| Batch: 477/522| Loss: 0.0015\n",
            "Epoch: 2 / 2| Batch: 478/522| Loss: 0.0004\n",
            "Epoch: 2 / 2| Batch: 479/522| Loss: 0.0007\n",
            "Epoch: 2 / 2| Batch: 480/522| Loss: 0.0022\n",
            "Epoch: 2 / 2| Batch: 481/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 482/522| Loss: 0.0182\n",
            "Epoch: 2 / 2| Batch: 483/522| Loss: 0.0253\n",
            "Epoch: 2 / 2| Batch: 484/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 485/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 486/522| Loss: 0.0020\n",
            "Epoch: 2 / 2| Batch: 487/522| Loss: 0.0059\n",
            "Epoch: 2 / 2| Batch: 488/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 489/522| Loss: 0.0327\n",
            "Epoch: 2 / 2| Batch: 490/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 491/522| Loss: 0.0846\n",
            "Epoch: 2 / 2| Batch: 492/522| Loss: 0.0016\n",
            "Epoch: 2 / 2| Batch: 493/522| Loss: 0.0255\n",
            "Epoch: 2 / 2| Batch: 494/522| Loss: 0.0001\n",
            "Epoch: 2 / 2| Batch: 495/522| Loss: 0.0029\n",
            "Epoch: 2 / 2| Batch: 496/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 497/522| Loss: 0.0006\n",
            "Epoch: 2 / 2| Batch: 498/522| Loss: 0.0508\n",
            "Epoch: 2 / 2| Batch: 499/522| Loss: 0.1388\n",
            "Epoch: 2 / 2| Batch: 500/522| Loss: 0.0138\n",
            "Epoch: 2 / 2| Batch: 501/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 502/522| Loss: 0.0923\n",
            "Epoch: 2 / 2| Batch: 503/522| Loss: 0.0036\n",
            "Epoch: 2 / 2| Batch: 504/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 505/522| Loss: 0.0083\n",
            "Epoch: 2 / 2| Batch: 506/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 507/522| Loss: 0.0006\n",
            "Epoch: 2 / 2| Batch: 508/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 509/522| Loss: 0.0039\n",
            "Epoch: 2 / 2| Batch: 510/522| Loss: 0.0003\n",
            "Epoch: 2 / 2| Batch: 511/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 512/522| Loss: 0.0262\n",
            "Epoch: 2 / 2| Batch: 513/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 514/522| Loss: 0.0009\n",
            "Epoch: 2 / 2| Batch: 515/522| Loss: 0.0079\n",
            "Epoch: 2 / 2| Batch: 516/522| Loss: 0.0111\n",
            "Epoch: 2 / 2| Batch: 517/522| Loss: 0.0017\n",
            "Epoch: 2 / 2| Batch: 518/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 519/522| Loss: 0.0006\n",
            "Epoch: 2 / 2| Batch: 520/522| Loss: 0.0000\n",
            "Epoch: 2 / 2| Batch: 521/522| Loss: 0.0005\n",
            "Epoch: 2 / 2| Batch: 522/522| Loss: 0.0000\n",
            "Total training time: 3.50 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "EC7DG0T26xXg"
      },
      "id": "EC7DG0T26xXg"
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy(dataloader, type):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        pred_scores = []\n",
        "        actual_scores = []\n",
        "        for batch in tqdm(dataloader, total=len(dataloader), desc=f'Calc {type} accuracy'):\n",
        "            prompt, targets = batch\n",
        "            encodings = tokenize_text(prompt)\n",
        "\n",
        "            input_ids = encodings['input_ids'].to(device)\n",
        "            attention_mask = encodings['attention_mask'].to(device)\n",
        "\n",
        "            with autocast():\n",
        "                logits = model(input_ids, attention_mask)\n",
        "                pred_score = F.softmax(logits, dim=-1).argmax(dim=-1).cpu().detach().numpy().tolist()\n",
        "                pred_scores.extend(pred_score)\n",
        "                actual_scores.extend(targets.numpy().tolist())\n",
        "\n",
        "        pred_scores = np.array(pred_scores)\n",
        "        accuracy = accuracy_score(actual_scores, pred_scores)\n",
        "\n",
        "        return accuracy"
      ],
      "metadata": {
        "id": "lKYSEfOC6yvf"
      },
      "id": "lKYSEfOC6yvf",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = calc_accuracy(train_dataloader, type='train')\n",
        "test_acc = calc_accuracy(test_dataloader, type='test')\n",
        "val_acc = calc_accuracy(val_dataloader, type='val')\n",
        "\n",
        "print('Train accuracy:', train_acc)\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Val accuracy:', val_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "d320aac6041d43a78fee841fcd5798e8",
            "d5a23d826cfa48d5ad578152d85c4791",
            "07edd70c43514cd992c6ef8cfe96a675",
            "c9033febce4e48ae9c456bd9895db62d",
            "1d08e473404f400aa17334ddb34a0a2f",
            "dadc52fcccf14542b832f90fb1163d85",
            "fda1df52c82a4c88b4a79199e9dd0e97",
            "aa44d75078684bedbee846342a67f1be",
            "9ffe69d9da4f4ddfb37c023866b8f17f",
            "97828387c6f84ed8ac270dacebf64e4b",
            "de157ec2497943d8b7cb4edca4872a45",
            "6bb0f6dd2351498fad01551e08e12764",
            "c696bee3a0e549db987c796564f77876",
            "14a75d4778064ff7b305ba2af16cbc3d",
            "3b25a107b406467a92e823c28b1f0555",
            "a6c10701d4cc42f6832f56e229aee9fe",
            "e8360d1369254775872220d122624ce0",
            "9a7e1de786bf4f639318beb27d4ce10c",
            "0e580ea70fd9451d8e61a66fd010d886",
            "60448421ec09458796b8b7de697b0b59",
            "ccd2016eb5174d0e9f30c23df6d844e6",
            "04b15b4ea69441d8b812293b91abd72d",
            "11481008d23a446a94f1128e350619eb",
            "05cf4e8512d047cdbbbef2502297585d",
            "567c5bab882f4b1da3df0cc90f8bebbb",
            "2dc027bc624e4986809a4fa77cc3ce9e",
            "bee14cc490e84ed68350991663cb98d0",
            "aab56d2a29a14d0faff79dadaa10afb1",
            "314e37dbaedf442586c25b0da3e246fa",
            "5782117ebb534ce78ec9ddd86c265680",
            "09d334f8e2684db5a09c8629c4bc522c",
            "a443bf3880f14a1fb3d105ffb3eae7b0",
            "0ca8e5cdcf9e47c79c9cef855d7e534f"
          ]
        },
        "id": "Z84KNZQF5OvX",
        "outputId": "0399147b-a26c-4211-b75e-b1f9978e621f"
      },
      "id": "Z84KNZQF5OvX",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Calc train accuracy:   0%|          | 0/522 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d320aac6041d43a78fee841fcd5798e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Calc test accuracy:   0%|          | 0/19 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bb0f6dd2351498fad01551e08e12764"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Calc val accuracy:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11481008d23a446a94f1128e350619eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 0.9971264367816092\n",
            "Test accuracy: 0.9733333333333334\n",
            "Val accuracy: 0.9932885906040269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Model        | Weights   | Trainable token | Trainable layers        | Context length                            | CPU/GPU | Training time | Training acc | Validation acc | Test acc |\n",
        "|--------------|-----------|-----------------|-------------------------|-------------------------------------------|---------|---------------|--------------|----------------|-----------|\n",
        "| h20-danube (1.8 B)| instruct   | last            | LoRA                    | dynamic padding (batch-wise)        | T4 (Colab free)    | 3.50 min      | 99.71%       | 99.32%         | 97.33%    |"
      ],
      "metadata": {
        "id": "TKXcWqnW4-Ox"
      },
      "id": "TKXcWqnW4-Ox"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yrcQ1NvWzLAn"
      },
      "id": "yrcQ1NvWzLAn",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "databundleVersionId": 8059942,
          "sourceId": 71485,
          "sourceType": "competition"
        },
        {
          "sourceId": 159748558,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 165914575,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 165914677,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 166361201,
          "sourceType": "kernelVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelInstanceId": 3900,
          "sourceId": 5112,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 17079.705434,
      "end_time": "2024-04-23T03:56:23.258603",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-04-22T23:11:43.553169",
      "version": "2.5.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d320aac6041d43a78fee841fcd5798e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5a23d826cfa48d5ad578152d85c4791",
              "IPY_MODEL_07edd70c43514cd992c6ef8cfe96a675",
              "IPY_MODEL_c9033febce4e48ae9c456bd9895db62d"
            ],
            "layout": "IPY_MODEL_1d08e473404f400aa17334ddb34a0a2f"
          }
        },
        "d5a23d826cfa48d5ad578152d85c4791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dadc52fcccf14542b832f90fb1163d85",
            "placeholder": "​",
            "style": "IPY_MODEL_fda1df52c82a4c88b4a79199e9dd0e97",
            "value": "Calc train accuracy: 100%"
          }
        },
        "07edd70c43514cd992c6ef8cfe96a675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa44d75078684bedbee846342a67f1be",
            "max": 522,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ffe69d9da4f4ddfb37c023866b8f17f",
            "value": 522
          }
        },
        "c9033febce4e48ae9c456bd9895db62d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97828387c6f84ed8ac270dacebf64e4b",
            "placeholder": "​",
            "style": "IPY_MODEL_de157ec2497943d8b7cb4edca4872a45",
            "value": " 522/522 [01:01&lt;00:00,  8.82it/s]"
          }
        },
        "1d08e473404f400aa17334ddb34a0a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dadc52fcccf14542b832f90fb1163d85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fda1df52c82a4c88b4a79199e9dd0e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa44d75078684bedbee846342a67f1be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ffe69d9da4f4ddfb37c023866b8f17f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97828387c6f84ed8ac270dacebf64e4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de157ec2497943d8b7cb4edca4872a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bb0f6dd2351498fad01551e08e12764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c696bee3a0e549db987c796564f77876",
              "IPY_MODEL_14a75d4778064ff7b305ba2af16cbc3d",
              "IPY_MODEL_3b25a107b406467a92e823c28b1f0555"
            ],
            "layout": "IPY_MODEL_a6c10701d4cc42f6832f56e229aee9fe"
          }
        },
        "c696bee3a0e549db987c796564f77876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8360d1369254775872220d122624ce0",
            "placeholder": "​",
            "style": "IPY_MODEL_9a7e1de786bf4f639318beb27d4ce10c",
            "value": "Calc test accuracy: 100%"
          }
        },
        "14a75d4778064ff7b305ba2af16cbc3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e580ea70fd9451d8e61a66fd010d886",
            "max": 19,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60448421ec09458796b8b7de697b0b59",
            "value": 19
          }
        },
        "3b25a107b406467a92e823c28b1f0555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccd2016eb5174d0e9f30c23df6d844e6",
            "placeholder": "​",
            "style": "IPY_MODEL_04b15b4ea69441d8b812293b91abd72d",
            "value": " 19/19 [00:07&lt;00:00,  2.94it/s]"
          }
        },
        "a6c10701d4cc42f6832f56e229aee9fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8360d1369254775872220d122624ce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a7e1de786bf4f639318beb27d4ce10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e580ea70fd9451d8e61a66fd010d886": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60448421ec09458796b8b7de697b0b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccd2016eb5174d0e9f30c23df6d844e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04b15b4ea69441d8b812293b91abd72d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11481008d23a446a94f1128e350619eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05cf4e8512d047cdbbbef2502297585d",
              "IPY_MODEL_567c5bab882f4b1da3df0cc90f8bebbb",
              "IPY_MODEL_2dc027bc624e4986809a4fa77cc3ce9e"
            ],
            "layout": "IPY_MODEL_bee14cc490e84ed68350991663cb98d0"
          }
        },
        "05cf4e8512d047cdbbbef2502297585d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aab56d2a29a14d0faff79dadaa10afb1",
            "placeholder": "​",
            "style": "IPY_MODEL_314e37dbaedf442586c25b0da3e246fa",
            "value": "Calc val accuracy: 100%"
          }
        },
        "567c5bab882f4b1da3df0cc90f8bebbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5782117ebb534ce78ec9ddd86c265680",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09d334f8e2684db5a09c8629c4bc522c",
            "value": 10
          }
        },
        "2dc027bc624e4986809a4fa77cc3ce9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a443bf3880f14a1fb3d105ffb3eae7b0",
            "placeholder": "​",
            "style": "IPY_MODEL_0ca8e5cdcf9e47c79c9cef855d7e534f",
            "value": " 10/10 [00:03&lt;00:00,  3.28it/s]"
          }
        },
        "bee14cc490e84ed68350991663cb98d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aab56d2a29a14d0faff79dadaa10afb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "314e37dbaedf442586c25b0da3e246fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5782117ebb534ce78ec9ddd86c265680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09d334f8e2684db5a09c8629c4bc522c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a443bf3880f14a1fb3d105ffb3eae7b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ca8e5cdcf9e47c79c9cef855d7e534f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}